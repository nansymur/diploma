---
title: "diplom"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
```

```{r include=FALSE}
library(tidyverse)
library(gtrendsR)
library(readxl)
library(writexl)
library(sf)
library(spdep)
library(ggplot2)
library(car)
library(lmtest)
library(stargazer)
library(spatialreg)
library(texreg)
library(dplyr)
library(plyr) 
library(caret) 
library(repr)
library(varhandle)
library(DT) 
```
Import data frame containing state names (e.g. "Alabama"), state codes
(e.g. "AL"), latitude, longitude, average temperature (degrees Celcius)
and precipitations (inches).

``` {r}
state_info<-read_excel("/Users/nastyamurach/Desktop/диплом/state_info.xlsx")
```

#данные за 2019 
```{r}
states <- paste0("US-",state.abb)


gtrends_orth19_knee<-gtrends(
keyword = c("knee brace"),
geo = "US",
time = "2019-01-01 2019-12-31",
low_search_volume = TRUE)
```

Create a database of zip code characteristics using US census API.

``` {r}
# Load the tidycensus package into your R session
library(tidycensus)
# Define your Census API key and set it with census_api_key()
api_key <- "adb17a79927311f38e26b60b23cac8393a7af0a2"
census_api_key(api_key,install=TRUE,overwrite = TRUE)
```

Load the catalog of variables from 1-year ACS 2019.

``` {r}
readRenviron("~/.Renviron")
variables <- load_variables(2019, "acs1", cache = TRUE)
```

```{#r}
# create subfolder for outputs
dir.create(file.path("Outputs1"), recursive = TRUE)

# save variables.csv for easy search of relevant ACS variables in Excel
write_xlsx(variables, "Outputs1/variables.xlsx") 
```

Get ACS data

``` {r}
##demographic 
names<-c( 
fem_0_5 = "B01001_027",
fem_5_9="B01001_028",
fem_10_14="B01001_029",
fem_15_17="B01001_030",
fem_18_19="B01001_031",
fem_20="B01001_032",
fem_21="B01001_033",
fem_22_24="B01001_034",
fem_25_29="B01001_035",
fem_30_34="B01001_036",
fem_35_39="B01001_037",
fem_40_44="B01001_038",
fem_45_49="B01001_039",
fem_50_54="B01001_040",
fem_55_59="B01001_041",
fem_60_61="B01001_042",
fem_62_64="B01001_043",
fem_65_66="B01001_044",
fem_67_69="B01001_045",
fem_70_74="B01001_046",
fem_75_79="B01001_047",
fem_80_84="B01001_048",
fem_85_over="B01001_049",
 
mal_0_4="B01001_003",
mal_5_9="B01001_004",
mal_10_14="B01001_005",
mal_15_17="B01001_006",
mal_18_19="B01001_007",
mal_20="B01001_008",
mal_21="B01001_009",
mal_22_24="B01001_010",
mal_25_29="B01001_011",
mal_30_34="B01001_012",
mal_35_39="B01001_013",
mal_40_44="B01001_014",
mal_45_49="B01001_015",
mal_50_54="B01001_016",
mal_55_59="B01001_017",
mal_60_61="B01001_018",
mal_62_64="B01001_019",
mal_65_66="B01001_020",
mal_67_69="B01001_021",
mal_70_74="B01001_022",
mal_75_79="B01001_023",
mal_80_84="B01001_024",
mal_85_over="B01001_025",

total="B02001_001",

# race
white="B02001_002",
black="B02001_003",
asian="B02001_005", 

##economical
household_inc_less_10 = "B19001_002", # in thousands $ (ltm inflation-adjusted)
household_inc_10_14 = "B19001_003" ,
household_inc_15_19 = "B19001_004",
household_inc_20_24 = "B19001_005", 
household_inc_25_29 = "B19001_006", 
household_inc_30_34 = "B19001_007", 
household_inc_35_39 = "B19001_008", 
household_inc_40_44 = "B19001_009", 
household_inc_45_49 = "B19001_010", 
household_inc_50_59 = "B19001_011", 
household_inc_60_74 = "B19001_012", 
household_inc_75_99 = "B19001_013", 
household_inc_100_124 = "B19001_014", 
household_inc_125_149 = "B19001_015", 
household_inc_150_199 = "B19001_016", 
household_inc_200_more = "B19001_017",  

# type of occupation
man_bus_sc_occ = "B08124_002", # Management, business, science, and arts occupations
serv_occ = "B08124_003", # Service
sal_off_occ = "B08124_004", # Sales and office occupations
constr_occ = "B08124_005",    #Natural resources, construction, and maintenance occupations
prod_transp_occ = "B08124_006", #Production, transportation, and material moving occupations
mil_occ = "B08124_007", # Military specific occupations

#class of worker
pr_wage_sal_work = "B08128_002", # Private wage and salary workers
local_govern_work = "B08128_006", # Local Government workers
stat_govern_work = "B08128_007", # State Government workers
fed_govern_work = "B08128_008", # Federal Government workers
self_empl = "B08128_009", # Self-employed in own not incorporated business workers
unpaid_fam_work = "B08128_010", # Unpaid family workers (housewives)

##social
# marital status
never_marr = "B06008_002",
marr = "B06008_003",
div = "B06008_004",
sep = "B06008_005",
widowed = "B06008_006"
)

```

Merged interest by region data with state codes so that the resulting
data frame has 3 columns: state, hits, keyword, state\_code

``` {r}
data_orth19_knee<-gtrends_orth19_knee$interest_by_region%>%
  replace_na(list(hits=0))%>%
  dplyr::select(-geo,-gprop,-keyword) %>%
  dplyr::rename("NAME"="location") %>%
  left_join(state_info)  
```

```{r}
# get ACS data on the features specified above
acs_data19<-get_acs("state",
                  variables=names,
                  survey="acs1",
                  geometry=TRUE,
                  year=2019,
                  output = "wide",
                  shift_geo = TRUE) # Shifting Alaska and Hawaii geometry

#acs_data19 = acs_data19 %>% separate(NAME, c("County","State"), sep = ",")
# remove margins of error - keep only estimates
acs_data19<-acs_data19%>%dplyr::select(-ends_with("M"))
acs_data19 <- acs_data19 %>% mutate(div_sep_wid = divE + sepE + widowedE) %>% dplyr::select(-divE, -sepE, -widowedE) 
```
 
Convert counts to % of total population
---------------------------------------
``` {r}
perc=dplyr::select(as.data.frame(acs_data19),fem_0_5E:div_sep_wid)/
  rep(as.data.frame(acs_data19)[,which(colnames(as.data.frame(acs_data19))=="totalE")],
      ncol(dplyr::select(as.data.frame(acs_data19),fem_0_5E:div_sep_wid)))*100
colnames(perc)<-paste0("perc_",colnames(perc))

acs_data19<-bind_cols(acs_data19,perc)%>%
  dplyr::select(!fem_0_5E:div_sep_wid,-perc_totalE)
```

Merge census data with Google trends data
-----------------------------------------

``` {r}
data19_knee<-data_orth19_knee %>% mutate(year = "2019") %>%
  left_join(acs_data19) 
```

#данные 2018

```{r}
gtrends_orth18_knee<-gtrends(
keyword = c("knee brace"),
geo = "US",
time = "2018-01-01 2018-12-31",
low_search_volume = TRUE)  
```

Merged interest by region data with state codes so that the resulting
data frame has 3 columns: state, hits, keyword, state\_code

```{r}
data_orth18_knee<-gtrends_orth18_knee$interest_by_region%>%
  replace_na(list(hits=0))%>%
  dplyr::select(-geo,-gprop,-keyword)%>%
  dplyr::rename("NAME"="location") %>%
  left_join(state_info)
```

```{r}
# get ACS data on the features specified above
acs_data18<-get_acs("state", 
                  variables=names,
                  survey="acs1",
                  geometry=TRUE,
                  year=2018,
                  output = "wide",
                  shift_geo = TRUE) # Shifting Alaska and Hawaii geometry

#acs_data18 = acs_data18 %>% separate(NAME, c("County","State"), sep = ",")
# remove margins of error - keep only estimates
acs_data18<-acs_data18%>%dplyr::select(-ends_with("M"))
acs_data18 <- acs_data18 %>% mutate(div_sep_wid = divE + sepE + widowedE) %>% dplyr::select(-divE, -sepE, -widowedE) 
```

Convert counts to % of total population
---------------------------------------

``` {r}
perc=dplyr::select(as.data.frame(acs_data18),fem_0_5E:div_sep_wid)/
  rep(as.data.frame(acs_data18)[,which(colnames(as.data.frame(acs_data18))=="totalE")],
      ncol(dplyr::select(as.data.frame(acs_data18),fem_0_5E:div_sep_wid)))*100
colnames(perc)<-paste0("perc_",colnames(perc))

acs_data18<-bind_cols(acs_data18,perc)%>%
  dplyr::select(!fem_0_5E:div_sep_wid,-perc_totalE)
```

``` {r}
data18_knee <- data_orth18_knee %>% dplyr::mutate(year = "2018") %>%
  left_join(acs_data18)  
```


#данные 2017

```{r}
gtrends_orth17_knee <-gtrends(
keyword = c("knee brace"),
geo = "US",
time = "2017-01-01 2017-12-31",
low_search_volume = TRUE)  
```

Merged interest by region data with state codes so that the resulting
data frame has 3 columns: state, hits, keyword, state\_code

```{r}
data_orth17_knee<-gtrends_orth17_knee$interest_by_region%>%
  replace_na(list(hits=0))%>%
  dplyr::select(-geo,-gprop,-keyword)%>%
  dplyr::rename("NAME"="location") %>%
  left_join(state_info)
```

```{r}
# get ACS data on the features specified above
acs_data17<-get_acs("state", 
                  variables=names,
                  survey="acs1",
                  geometry=TRUE,
                  year=2017,
                  output = "wide",
                  shift_geo = TRUE) # Shifting Alaska and Hawaii geometry

#acs_data18 = acs_data18 %>% separate(NAME, c("County","State"), sep = ",")
# remove margins of error - keep only estimates
acs_data17<-acs_data17%>%dplyr::select(-ends_with("M"))
acs_data17 <- acs_data17 %>% mutate(div_sep_wid = divE + sepE + widowedE) %>% dplyr::select(-divE, -sepE, -widowedE) 
```

Convert counts to % of total population
---------------------------------------

``` {r}
perc=dplyr::select(as.data.frame(acs_data17),fem_0_5E:div_sep_wid)/
  rep(as.data.frame(acs_data17)[,which(colnames(as.data.frame(acs_data17))=="totalE")],
      ncol(dplyr::select(as.data.frame(acs_data17),fem_0_5E:div_sep_wid)))*100
colnames(perc)<-paste0("perc_",colnames(perc))

acs_data17<-bind_cols(acs_data17,perc)%>%
  dplyr::select(!fem_0_5E:div_sep_wid,-perc_totalE)
```

``` {r}
data17_knee<- data_orth17_knee %>% mutate(year = "2017") %>%
  left_join(acs_data17)  
```

#данные 2016

```{r}
gtrends_orth16_knee<-gtrends(
keyword = c("knee brace"),
geo = "US",
time = "2016-01-01 2016-12-31",
low_search_volume = TRUE)
```

Merged interest by region data with state codes so that the resulting
data frame has 3 columns: state, hits, keyword, state\_code

```{r}
data_orth16_knee<-gtrends_orth16_knee$interest_by_region%>%
  replace_na(list(hits=0))%>%
  dplyr::select(-geo, -gprop,-keyword)%>%
  dplyr::rename("NAME"="location") %>%
  left_join(state_info)
```

```{r}
# get ACS data on the features specified above
acs_data16<-get_acs("state", 
                  variables=names,
                  survey="acs1",
                  geometry=TRUE,
                  year=2016,
                  output = "wide",
                  shift_geo = TRUE) # Shifting Alaska and Hawaii geometry

#acs_data18 = acs_data18 %>% separate(NAME, c("County","State"), sep = ",")
# remove margins of error - keep only estimates
acs_data16<-acs_data16%>%dplyr::select(-ends_with("M"))
acs_data16 <- acs_data16 %>% mutate(div_sep_wid = divE + sepE + widowedE) %>% dplyr::select(-divE, -sepE, -widowedE) 
```

Convert counts to % of total population
---------------------------------------

``` {r}
perc=dplyr::select(as.data.frame(acs_data16),fem_0_5E:div_sep_wid)/
  rep(as.data.frame(acs_data16)[,which(colnames(as.data.frame(acs_data16))=="totalE")],
      ncol(dplyr::select(as.data.frame(acs_data16),fem_0_5E:div_sep_wid)))*100
colnames(perc)<-paste0("perc_",colnames(perc))

acs_data16<-bind_cols(acs_data16,perc)%>%
  dplyr::select(!fem_0_5E:div_sep_wid,-perc_totalE)
```

``` {r}
data16_knee<- data_orth16_knee %>% mutate(year = "2016") %>%
  left_join(acs_data16)  
```

#данные 2015

```{r}
gtrends_orth15_knee<-gtrends(
keyword = c("knee brace"),
geo = "US",
time = "2015-01-01 2015-12-31",
low_search_volume = TRUE)
```

Merged interest by region data with state codes so that the resulting
data frame has 3 columns: state, hits, keyword, state\_code

```{r}
data_orth15_knee<-gtrends_orth15_knee$interest_by_region%>%
  replace_na(list(hits=0))%>%
  dplyr::select(-geo, -gprop,-keyword)%>%
  dplyr::rename("NAME"="location") %>%
  left_join(state_info)
```

```{r}
# get ACS data on the features specified above
acs_data15<-get_acs("state", 
                  variables=names,
                  survey="acs1",
                  geometry=TRUE,
                  year=2015,
                  output = "wide",
                  shift_geo = TRUE) # Shifting Alaska and Hawaii geometry

#acs_data18 = acs_data18 %>% separate(NAME, c("County","State"), sep = ",")
# remove margins of error - keep only estimates
acs_data15<-acs_data15%>%dplyr::select(-ends_with("M"))
acs_data15 <- acs_data15 %>% mutate(div_sep_wid = divE + sepE + widowedE) %>% dplyr::select(-divE, -sepE, -widowedE) 
```

Convert counts to % of total population
---------------------------------------

``` {r}
perc=dplyr::select(as.data.frame(acs_data15),fem_0_5E:div_sep_wid)/
  rep(as.data.frame(acs_data15)[,which(colnames(as.data.frame(acs_data15))=="totalE")],
      ncol(dplyr::select(as.data.frame(acs_data15),fem_0_5E:div_sep_wid)))*100
colnames(perc)<-paste0("perc_",colnames(perc))

acs_data15<-bind_cols(acs_data15,perc)%>%
  dplyr::select(!fem_0_5E:div_sep_wid,-perc_totalE)
```

``` {r}
data15_knee<- data_orth15_knee %>% mutate(year = "2015") %>%
  left_join(acs_data15)  
```

##Соеденим датасеты за несколько лет

```{r} 
data_knee = rbind(data19_knee, data18_knee, data17_knee, data16_knee, data15_knee)
data_knee = data_knee %>% dplyr::select(-geometry, -GEOID)
```


remove E - the last character of some column names
--------------------------------------------------

``` {r}
colnames(data_knee)<-ifelse(substr(colnames(data_knee),nchar(colnames(data_knee)),
                              nchar(colnames(data_knee)))=="E"&
                         !colnames(data_knee) %in% c("NAME","latitude","longitude"), 
                       substr(colnames(data_knee),1,nchar(colnames(data_knee))-1),
                       colnames(data_knee))

#write.csv(data_knee, "data_knee.csv", row.names = F)
data = data_knee
```

```{r}
data = data %>% mutate(perc_fem_20_21 = perc_fem_20 + perc_fem_21) 
data = data %>% dplyr::select(-perc_fem_21, -perc_fem_20)
data = data %>% mutate(perc_mal_20_21 = perc_mal_20 + perc_mal_21) 
data = data %>% dplyr::select(-perc_mal_21, -perc_mal_20)

data = data %>% mutate(perc_fem_0_9 = perc_fem_0_5 + perc_fem_5_9)
data = data %>% mutate(perc_fem_10_17 = perc_fem_10_14 + perc_fem_15_17)
data = data %>% mutate(perc_fem_18_21 = perc_fem_18_19 + perc_fem_20_21)
data = data %>% mutate(perc_fem_22_29 = perc_fem_22_24 + perc_fem_25_29)
data = data %>% mutate(perc_fem_30_39 = perc_fem_30_34 + perc_fem_35_39)
data = data %>% mutate(perc_fem_40_49 = perc_fem_40_44 + perc_fem_45_49)
data = data %>% mutate(perc_fem_50_59 = perc_fem_50_54 + perc_fem_55_59)
data = data %>% mutate(perc_fem_60_66 = perc_fem_60_61 + perc_fem_62_64 + perc_fem_65_66)
data = data %>% mutate(perc_fem_67_79 = perc_fem_67_69 + perc_fem_70_74 + perc_fem_75_79)
data = data %>% mutate(perc_fem_80_85 = perc_fem_80_84 + perc_fem_85_over)

data = data %>% mutate(perc_mal_0_9 = perc_mal_0_4 + perc_mal_5_9)
data = data %>% mutate(perc_mal_10_17 = perc_mal_10_14 + perc_mal_15_17)
data = data %>% mutate(perc_mal_18_21 = perc_mal_18_19 + perc_mal_20_21)
data = data %>% mutate(perc_mal_22_29 = perc_mal_22_24 + perc_mal_25_29)
data = data %>% mutate(perc_mal_30_39 = perc_mal_30_34 + perc_mal_35_39)
data = data %>% mutate(perc_mal_40_49 = perc_mal_40_44 + perc_mal_45_49)
data = data %>% mutate(perc_mal_50_59 = perc_mal_50_54 + perc_mal_55_59)
data = data %>% mutate(perc_mal_60_66 = perc_mal_60_61 + perc_mal_62_64 + perc_mal_65_66)
data = data %>% mutate(perc_mal_67_79 = perc_mal_67_69 + perc_mal_70_74 + perc_mal_75_79)
data = data %>% mutate(perc_mal_80_85 = perc_mal_80_84 + perc_mal_85_over)

data = data %>% dplyr::select(-perc_fem_0_5, -perc_fem_5_9, -perc_fem_10_14, -perc_fem_15_17, -perc_fem_18_19, -perc_fem_20_21, -perc_fem_22_24, -perc_fem_25_29, -perc_fem_30_34, -perc_fem_35_39, -perc_fem_40_44, -perc_fem_45_49, -perc_fem_50_54, -perc_fem_55_59, -perc_fem_60_61, -perc_fem_62_64, -perc_fem_65_66, -perc_fem_67_69, -perc_fem_70_74, -perc_fem_75_79, -perc_fem_80_84, -perc_fem_85_over)

data = data %>% dplyr::select(-perc_mal_0_4, -perc_mal_5_9, -perc_mal_10_14, -perc_mal_15_17, -perc_mal_18_19, -perc_mal_20_21, -perc_mal_22_24, -perc_mal_25_29, -perc_mal_30_34, -perc_mal_35_39, -perc_mal_40_44, -perc_mal_45_49, -perc_mal_50_54, -perc_mal_55_59, -perc_mal_60_61, -perc_mal_62_64, -perc_mal_65_66, -perc_mal_67_69, -perc_mal_70_74, -perc_mal_75_79, -perc_mal_80_84, -perc_mal_85_over)
```

```{r}
data = data %>% mutate(perc_household_income_less_14 = perc_household_inc_less_10 + perc_household_inc_10_14)
data = data %>% mutate(perc_household_income_15_24 = perc_household_inc_15_19 + perc_household_inc_20_24)
data = data %>% mutate(perc_household_income_25_34 = perc_household_inc_25_29 + perc_household_inc_30_34)
data = data %>% mutate(perc_household_income_35_44 = perc_household_inc_35_39 + perc_household_inc_40_44)
data = data %>% mutate(perc_household_income_45_59 = perc_household_inc_45_49 + perc_household_inc_50_59)   
data = data %>% mutate(perc_household_income_60_99 = perc_household_inc_60_74 + perc_household_inc_75_99)   
data = data %>% mutate(perc_household_income_100_149 = perc_household_inc_100_124 + perc_household_inc_125_149)  
data = data %>% mutate(perc_household_income_150_more = perc_household_inc_150_199 + perc_household_inc_200_more)
 
data = data %>% dplyr::select(-perc_household_inc_less_10, -perc_household_inc_10_14, -perc_household_inc_15_19, -perc_household_inc_20_24, -perc_household_inc_25_29, -perc_household_inc_30_34, -perc_household_inc_35_39, -perc_household_inc_40_44, -perc_household_inc_45_49, -perc_household_inc_50_59, -perc_household_inc_60_74, -perc_household_inc_75_99, -perc_household_inc_100_124, -perc_household_inc_125_149, -perc_household_inc_150_199, -perc_household_inc_200_more) 
```

---------------------------
females and males
---------------------------
```{r} 
library(ggpubr)
median_fem_less_9 <- summarize(data, age_less_9  = median(perc_fem_0_9))
f_09 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_fem_0_9, xlab = "State")) +
    geom_boxplot()  +
 geom_hline( yintercept = as.numeric(median_fem_less_9)) + 
  coord_flip()

median_fem_10_17 <- summarize(data, age_10_17 = median(perc_fem_10_17))
f_10_17 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_fem_10_17, xlab = "State")) +
  geom_hline( yintercept = as.numeric(median_fem_10_17)) + 
    geom_boxplot() + coord_flip()

median_fem_18_21 <- summarize(data, age_18_21 = median(perc_fem_18_21))
f_18_21 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_fem_18_21, xlab = "State")) + geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_fem_18_21)) + coord_flip()

median_fem_22_29 <- summarize(data, age_22_29 = median(perc_fem_22_29))
f_22_29 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_fem_22_29, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_fem_22_29)) + coord_flip()

median_fem_30_39 <- summarize(data, age_30_39 = median(perc_fem_30_39))
f_30_39 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_fem_30_39, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_fem_30_39)) + coord_flip()

median_fem_40_49 <- summarize(data, age_40_49 = median(perc_fem_40_49))
f_40_49 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_fem_40_49, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_fem_40_49)) +  coord_flip()

median_fem_50_59 <- summarize(data, age_50_59 = median(perc_fem_50_59))
f_50_59 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_fem_50_59, xlab = "State")) +
    geom_boxplot() + 
   geom_hline( yintercept = as.numeric(median_fem_50_59)) + coord_flip()

median_fem_60_66 <- summarize(data, age_60_66 = median(perc_fem_60_66))
f_60_66 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_fem_60_66, xlab = "State")) +
    geom_boxplot() + 
   geom_hline( yintercept = as.numeric(median_fem_60_66)) + coord_flip()

median_fem_67_79 <- summarize(data, age_67_79 = median(perc_fem_67_79))
f_67_79 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_fem_67_79, xlab = "State")) +
    geom_boxplot() + 
   geom_hline( yintercept = as.numeric(median_fem_67_79)) + coord_flip()

median_fem_80_85 <- summarize(data, age_80_85 = median(perc_fem_80_85))
f_80_85 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_fem_80_85, xlab = "State")) +
    geom_boxplot() + 
   geom_hline( yintercept = as.numeric(median_fem_80_85)) + coord_flip()

ggarrange(f_09, f_10_17, f_18_21, f_22_29, f_30_39)
ggarrange(f_40_49, f_50_59, f_60_66, f_67_79, f_80_85)  

fem_data <- data.frame(c(round(median_fem_less_9, 2), round(median_fem_10_17, 2), round(median_fem_18_21, 2), round(median_fem_22_29, 2), round(median_fem_30_39, 2), round(median_fem_40_49, 2), round(median_fem_50_59, 2), round(median_fem_60_66, 2), round(median_fem_67_79, 2), round(median_fem_80_85, 2)))
```

```{r}
### males
median_mal_less_9 <- summarize(data, age_less_9 = median(perc_fem_0_9))
m_09 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_mal_0_9, xlab = "State")) +
    geom_boxplot()  +
 geom_hline( yintercept = as.numeric(median_mal_less_9)) + 
  coord_flip()

median_mal_10_17 <- summarize(data, age_10_17 = median(perc_mal_10_17))
m_10_17 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_mal_10_17, xlab = "State")) +
  geom_hline( yintercept = as.numeric(median_mal_10_17)) + 
    geom_boxplot() + coord_flip()

median_mal_18_21 <- summarize(data, age_18_21 = median(perc_mal_18_21))
m_18_21 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_mal_18_21, xlab = "State")) + geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_mal_18_21)) + coord_flip()

median_mal_22_29 <- summarize(data, age_22_29 = median(perc_mal_22_29))
m_22_29 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_mal_22_29, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_mal_22_29)) + coord_flip()

median_mal_30_39 <- summarize(data, age_30_39 = median(perc_mal_30_39))
m_30_39 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_mal_30_39, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_mal_30_39)) + coord_flip()

median_mal_40_49 <- summarize(data, age_40_49 = median(perc_mal_40_49))
m_40_49 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_mal_40_49, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_mal_40_49)) +  coord_flip()

median_mal_50_59 <- summarize(data, age_50_59 = median(perc_mal_50_59))
m_50_59 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_mal_50_59, xlab = "State")) +
    geom_boxplot() + 
   geom_hline( yintercept = as.numeric(median_mal_50_59)) + coord_flip()

median_mal_60_66 <- summarize(data, age_60_66 = median(perc_mal_60_66))
m_60_66 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_mal_60_66, xlab = "State")) +
    geom_boxplot() + 
   geom_hline( yintercept = as.numeric(median_mal_60_66)) + coord_flip()

median_mal_67_79 <- summarize(data, age_67_79 = median(perc_mal_67_79))
m_67_79 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_mal_67_79, xlab = "State")) +
    geom_boxplot() + 
   geom_hline( yintercept = as.numeric(median_mal_67_79)) + coord_flip()

median_mal_80_85 <- summarize(data, age_80_85 = median(perc_mal_80_85))
m_80_85 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_mal_80_85, xlab = "State")) +
    geom_boxplot() + 
   geom_hline( yintercept = as.numeric(median_mal_80_85)) + coord_flip()

ggarrange(m_09, m_10_17, m_18_21, m_22_29, m_30_39)
ggarrange(m_40_49, m_50_59, m_60_66, m_67_79, m_80_85)

mal_data <- data.frame(c(round(median_mal_less_9, 2), round(median_mal_10_17, 2), round(median_mal_18_21, 2), round(median_mal_22_29, 2), round(median_mal_30_39, 2), round(median_mal_40_49, 2), round(median_mal_50_59, 2), round(median_mal_60_66, 2), round(median_mal_67_79, 2), round(median_mal_80_85, 2)))
```
# district of Columbia is different from other states, there comparatably lower percent of females in the age 10-17
# and  higher in the age 18-29 
# according our data the biggest proportion in the age of 50-59 (6% - 7.5%)

## distribution of males in the age 0-9 is higher than females in this age (5%-7% vs 5.5%-6.5%)
## according to distribution of males and females in the age 60-66 -> perc of males alittle bit lower (3.5% to 4.5% vs 4% to 5%)
## males in the age of 80-85 is lower than females (1%-2% and 2%-3%, correspondingly)
 
```{r}
data_fem_mal = rbind(fem_data, mal_data)
transposed_data <-  data.frame(t(data_fem_mal))
rownames(data_fem_mal) <- c("females", "males")
transposed_data %>% mutate(diff = X1-X2) 
```

```{r}
data_fem = data %>% dplyr::select(perc_fem_0_9, perc_fem_10_17, perc_fem_18_21, perc_fem_22_29, perc_fem_30_39, perc_fem_40_49, perc_fem_50_59, perc_fem_60_66, perc_fem_67_79, perc_fem_80_85)

data_mal = data %>% dplyr::select(perc_mal_0_9, perc_mal_10_17, perc_mal_18_21, perc_mal_22_29, perc_mal_30_39, perc_mal_40_49, perc_mal_50_59, perc_mal_60_66, perc_mal_67_79, perc_mal_80_85)

library(pastecs)
datatable(head(round(stat.desc(data_fem), 4)[c(4:6, 8, 13),]), class = 'cell-border stripe', options = list(
  initComplete = JS(
    "function(settings, json) {",
    "$(this.api().table().header()).css({'font-size': '14px'});",
    "}"))) %>%  formatStyle(columns = colnames(.$x$data), `font-size` = '15px')  
                                                                                                       
datatable(head(round(stat.desc(data_mal), 4)[c(4:6, 8, 13),]), class = 'cell-border stripe', 
          options = list(
  initComplete = JS(
    "function(settings, json) {",
    "$(this.api().table().header()).css({'font-size': '14px'});",
    "}"))) %>%  formatStyle(columns = colnames(.$x$data), `font-size` = '15px')  
```

---------------------------
race 
---------------------------
```{r} 
library(ggpubr)
median_white <- summarize(data, median = median(perc_white))
white <- ggplot(data = data, mapping = aes(x = NAME, y = perc_white, xlab = "State")) +
    geom_boxplot()  +
 geom_hline( yintercept = as.numeric(median_white)) + 
  coord_flip()

median_black <- summarize(data, median = median(perc_black))
black <- ggplot(data = data, mapping = aes(x = NAME, y = perc_black, xlab = "State")) +
  geom_hline( yintercept = as.numeric(median_black)) + 
    geom_boxplot() + coord_flip()

median_asian <- summarize(data, median = median(perc_asian))
asian <- ggplot(data = data, mapping = aes(x = NAME, y = perc_asian, xlab = "State")) + geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_asian)) + coord_flip()
 
ggarrange(white, black)
ggarrange(asian) 
```
# the lowest proportion of white people in District of Columbia and Hawaii. Overall the proportion between 60%-90% 
# the biggest proportion of asian in Hawaii (near 40%), in California near 15%, in other states the proprotion does not exceeds 10%
# the biggest proportion of black people in Dictrict of Columbia (50%+), in Mississipi near 37%. The distribution according the states 0%-30%. Almost 0% i Montana, Idaho, Wyoming, New Hampshire

---------------------------
household_income
---------------------------
```{r}  
median_household_19<-get_acs("state",
                  variables=c("B19013_001"),
                  survey="acs1",
                  geometry=TRUE,
                  year=2019,
                  output = "wide",
                  shift_geo = TRUE)
# median household income = 68703 $ 
 
a = median_household_19$NAME
b = median_household_19$B19013_001E/1000
median_household_19 = data.frame(a,b)

median_household_15<-get_acs("state",
                  variables=c("B19013_001"),
                  survey="acs1",
                  geometry=TRUE,
                  year=2015,
                  output = "wide",
                  shift_geo = TRUE)
# median household income = 68703 $ 

c = median_household_15$NAME
d = median_household_15$B19013_001E/1000
median_household_15 = data.frame(c,d) 
  
median_household_15 = median_household_15 %>% dplyr::select(NAME, B19013_001E, -geometry)
```

```{r}
library(ggpubr)
median_less_14 <- summarize(data, median = median(perc_household_income_less_14))
p_14 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_household_income_less_14, xlab = "State")) +
    geom_boxplot()  +
 geom_hline( yintercept = as.numeric(median_less_14)) + 
  coord_flip()

median_15_24 <- summarize(data, median = median(perc_household_income_15_24))
p_15_24 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_household_income_15_24, xlab = "State")) +
  geom_hline( yintercept = as.numeric(median_15_24)) + 
    geom_boxplot() + coord_flip()

median_25_34 <- summarize(data, median = median(perc_household_income_25_34))
p_25_34 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_household_income_25_34, xlab = "State")) + geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_25_34)) + coord_flip()

median_35_44 <- summarize(data, median = median(perc_household_income_35_44))
p_35_44 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_household_income_35_44, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_35_44)) + coord_flip()

median_45_59 <- summarize(data, median = median(perc_household_income_45_59))
p_45_59 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_household_income_45_59, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_45_59)) + coord_flip()

median_60_99 <- summarize(data, median = median(perc_household_income_60_99))
p_60_99 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_household_income_60_99, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_60_99)) +  coord_flip()

median_100_149 <- summarize(data, median = median(perc_household_income_100_149))
p_100_149 <- ggplot(data = data, mapping = aes(x = NAME, y = perc_household_income_100_149, xlab = "State")) +
    geom_boxplot() + 
   geom_hline( yintercept = as.numeric(median_100_149)) + coord_flip()

median_150_more <- summarize(data, median = median(perc_household_income_150_more))
p_150_more <- ggplot(data = data, mapping = aes(x = NAME, y = perc_household_income_150_more, xlab = "State")) +
    geom_boxplot() + 
   geom_hline( yintercept = as.numeric(median_150_more)) + coord_flip()


ggarrange(p_14, p_15_24, p_25_34, p_35_44)
ggarrange(p_45_59, p_60_99, p_100_149, p_150_more)  
```

```{r}
household_income <- data %>% dplyr::select(perc_household_income_less_14, perc_household_income_15_24, perc_household_income_25_34, perc_household_income_35_44, perc_household_income_45_59, perc_household_income_60_99, perc_household_income_100_149, perc_household_income_150_more) 
colnames(household_income) <- c("income_less_14", "income_15_24", "income_25_34", "income_35_44", "income_45_59", "income_60_99", "income_100_149", "income_150+")
  
datatable(head(round(stat.desc(household_income), 4)[c(4:6, 8, 13),]), class = 'cell-border stripe', 
          options = list(
  initComplete = JS(
    "function(settings, json) {",
    "$(this.api().table().header()).css({'font-size': '14px'});",
    "}"))) %>%  formatStyle(columns = colnames(.$x$data), `font-size` = '14px') 
```
# the biggest proportion of household income less $14 thousands in Mississipi, District of Columbia, West Virginia, Alabama; the smallest proportion in Utah, Alaska, Hawaii
# in Hawaii is proportion of income is the biggest in the income_100_149
# the biggest proportion of people with income higher 150 in Distrcit of Columbia (10%), Washington, Virginia, New Mexico, New Jersey, Massachusetts, Maryland

---------------------------
occupation
---------------------------
```{r} 
library(ggpubr)

median_man_bus_sc_occ <- summarize(data, median = median(perc_man_bus_sc_occ))
occ_man_bus_sc <- ggplot(data = data, mapping = aes(x = NAME, y = perc_man_bus_sc_occ, xlab = "State")) +
    geom_boxplot()  +
 geom_hline( yintercept = as.numeric(median_man_bus_sc_occ)) + 
  coord_flip()

median_ser_occ <- summarize(data, median = median(perc_serv_occ))
occ_serv <- ggplot(data = data, mapping = aes(x = NAME, y = perc_serv_occ, xlab = "State")) +
  geom_hline( yintercept = as.numeric(median_ser_occ)) + 
    geom_boxplot() + coord_flip()

median_sal_off_occ  <- summarize(data, median = median(perc_sal_off_occ))
occ_sal_off <- ggplot(data = data, mapping = aes(x = NAME, y = perc_sal_off_occ, xlab = "State")) + geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_sal_off_occ)) + coord_flip()

median_constr_occ <- summarize(data, median = median(perc_constr_occ))
occ_constr <- ggplot(data = data, mapping = aes(x = NAME, y = perc_constr_occ, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_constr_occ)) + coord_flip()

median_prod_transp_occ <- summarize(data, median = median(perc_prod_transp_occ))
occ_prod_transp <- ggplot(data = data, mapping = aes(x = NAME, y = perc_prod_transp_occ, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_prod_transp_occ)) + coord_flip()

median_mil_occ <- summarize(data, median = median(perc_mil_occ))
occ_mil <- ggplot(data = data, mapping = aes(x = NAME, y = perc_mil_occ, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_mil_occ)) +  coord_flip()

ggarrange(occ_man_bus_sc, occ_serv)
ggarrange(occ_constr, occ_prod_transp)
ggarrange(occ_mil)  
```
# the biggest proportion of management, business and science in District of Columbia (near 35%), in other states it is also the most popular occupation (10%-25%)
# the biggest proprortion of service occupation in Nevada and Hawaii  (10% - 12%), overall - 7% - 10%
# the majority proportion of construction ccupation in Wyoming (near 8%) and the least in District of Columbia. The proportion of across states - 4%-6%
# The least proportion of production and transportation in District of Columbia (2%), the biggest proportion in Wisconsin and Indiana (9%). Overall - 4%-8%
# the biggest proportion of military occupation in Hawaii (2%) and Alaska (1%). Overall - 0% - 0.5%. 

---------------------------
class of worker
--------------------------- 
```{r} 
library(ggpubr)

median_pr_sal <- summarize(data, median = median(perc_pr_wage_sal_work))
wage_pr_sal <- ggplot(data = data, mapping = aes(x = NAME, y = perc_pr_wage_sal_work, xlab = "State")) +
    geom_boxplot()  +
 geom_hline( yintercept = as.numeric(median_pr_sal)) + 
  coord_flip()

median_loc_govern <- summarize(data, median = median(perc_local_govern_work))
wage_loc_govern <- ggplot(data = data, mapping = aes(x = NAME, y = perc_local_govern_work, xlab = "State")) +
  geom_hline( yintercept = as.numeric(median_loc_govern)) + 
    geom_boxplot() + coord_flip()

median_stat_govern  <- summarize(data, median = median(perc_stat_govern_work ))
wage_stat_govern <- ggplot(data = data, mapping = aes(x = NAME, y = perc_stat_govern_work, xlab = "State")) + geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_stat_govern)) + coord_flip()

median_fed_govern <- summarize(data, median = median(perc_fed_govern_work))
wage_fed_govern <- ggplot(data = data, mapping = aes(x = NAME, y = perc_fed_govern_work, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_fed_govern)) + coord_flip()

median_self_empl <- summarize(data, median = median(perc_self_empl))
wage_self <- ggplot(data = data, mapping = aes(x = NAME, y = perc_self_empl, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_self_empl)) + coord_flip()

median_unp_fam <- summarize(data, median = median(perc_unpaid_fam_work))
wage_unpaid <- ggplot(data = data, mapping = aes(x = NAME, y = perc_unpaid_fam_work, xlab = "State")) +
    geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_unp_fam)) +  coord_flip()

ggarrange(wage_pr_sal, wage_loc_govern)
ggarrange(wage_stat_govern, wage_fed_govern)
ggarrange(wage_self, wage_unpaid)  
```
# the biggest proprotion of private and salary workers (30-35%)
# the propotion of types of governemnt work is almost identical.
# in Wyoming the biggest proportion if local governemnt work, state work - in Hawaii, federal - in Disctrict of Columbia (10%). The different level of proportion in Virginia, Maryland, Hawaii, Alasca
# the biggest procent of self-employment in Vermont (5%), a little bit smaller - in South and North Dakota, Nebrasca, Maine
# the biggest proportion of unpaid family work in Wyoming, Montana.  But overall unpaid family workers outnumbered comparing other class works

---------------------------
marital status 
---------------------------
```{r} 
library(ggpubr)
median_marr <- summarize(data, median = median(perc_marr))
marr <- ggplot(data = data, mapping = aes(x = NAME, y = perc_marr, xlab = "State")) +
    geom_boxplot()  +
 geom_hline( yintercept = as.numeric(median_marr)) + 
  coord_flip()

median_nevmarr <- summarize(data, median = median(perc_never_marr))
nevmarr <- ggplot(data = data, mapping = aes(x = NAME, y = perc_never_marr, xlab = "State")) +
  geom_hline( yintercept = as.numeric(median_nevmarr)) + 
    geom_boxplot() + coord_flip()

median_notmarr <- summarize(data, median = median(perc_div_sep_wid))
notmarr <- ggplot(data = data, mapping = aes(x = NAME, y = perc_div_sep_wid, xlab = "State")) + geom_boxplot() + 
  geom_hline( yintercept = as.numeric(median_notmarr)) + coord_flip()
 
ggarrange(marr, nevmarr)
ggarrange(notmarr) 
```
## least percent of married in Disctrict of Columbia (23-25%), near 35% in Louisiana, Missisipi and New Mexico. One of the states with highest proportion married people is Wyoming (reached 45%), near 42-43% in New Hampshire, Idaho, Montana. The median value is close to 40%. 
## Never married: the biggest proportion in District of Columbia (between 45 and 50%). The median value is near 27% across the states. Higher than 30% in New York,Massachusetts, Rhode Island. The least proportion in Wyoming, Idaho, Arkansas, Utah.
## The category united diversed, separeted and widowed is smallest, the median is slightly higher 15%. In West Virginia is the biggest proportion of this category. Higher than the median approximately at 2% in Maine, Kentucky, Florida, Arkansas, Alabama.
#The smallest in Utah (slightly higher than 10%). In District of Columbia, Rhode Island, Wyoming as well as in South Dakota the proportion was changing over the time on 0.5-0.75%
 


```{#r}
# Check for variation by state.
data %>% 
  group_by(NAME) %>% # ensures that subsequent functions will be performed by state
  dplyr::select(-year) %>% 
  summarise_all(sd) # sd is standard deviation 
# the biggest difference by hits -> that means over the years the values changes across states

# Check for variation by year.
data %>% 
  group_by(year) %>% 
  dplyr::select(-year) %>% # the "-" indicates variables to be removed
  summarise_all(sd)

# the biggest deviance by hits -> almost the same over the years
# the biggest difference within years can be seen for races features, but the size of the deviance almost did not change

# Check for variation by year.
data %>% 
  group_by(year) %>% 
  dplyr::select(-year, -NAME) %>% # the "-" indicates variables to be removed
  summarise_all(sd)

library(plm)
pvar(data)
```

Summary statistics (saved to file)
----------------------------------
##hits - запросы на орт товары
#create a summary table
```{#r}
stargazer(select(as.data.frame(data),hits,temperature_celcius,                               precipitation_inches,perc_black,perc_asian,perc_fem_45_49),
          out="Outputs1/Summary_table.htm",
          title="Table1. Summary statistics")
``` 
 

Hits over the time
------------------
```{r} 
data_orth15 %>% dplyr::select(NAME, hits) %>% head()
data_orth16 %>% dplyr::select(NAME, hits) %>% head()
data_orth17 %>% dplyr::select(NAME, hits) %>% head()
data_orth18 %>% dplyr::select(NAME, hits) %>% head()
data_orth19 %>% dplyr::select(NAME, hits) %>% head()

```

Correlation plot
----------------

acs data 2015-2019
```{r}
library("gplots")
data_cor = data %>% dplyr::select(-hits)
correl<-as.matrix(cor(select_if(as.data.frame(data_cor),is.numeric), method = "spearman"))
heatmap.2(correl, Colv=NA, Rowv=NA, scale = "none", col = bluered(100), 
          trace = "none", density.info = "none")
```

Candidate predictors were chosen on the basis of correlations higher
than 0.2 and age groups with almost identical correlations were merged.

``` {r}
correl<-as.data.frame(cor(select_if(as.data.frame(data),is.numeric), method = "spearman"))
 

correl$variable=row.names(correl)

ggplot(subset(correl,!variable=="hits"),
              aes(y=reorder(variable, hits),x=hits))+
         geom_col()+
         theme_minimal()+
  labs(y="Variable",x="Correlation with interest in knee brace")
```

Lowest smoothing of pairwise relationships

``` {r}  
ggplot(data=data,aes(x=perc_mal_60_66,y=hits,label=state_code))+
  geom_text(size=3,check_overlap = TRUE)+
  geom_smooth()+
  labs(x="perc~",
       y="Orth_product Interest")
```

# in order to decrease the correlation, we delete the males under 30 years, as we observed the similar trend among these age groups 
```{r} 
data = data %>% dplyr::select(-state_code, -perc_mal_0_9, -perc_mal_10_17, -perc_mal_18_21, -perc_mal_22_29, -perc_never_marr)
data1 = data
```

```{r} 
data1$NAME = as.factor(data1$NAME)
data1$year = as.factor(data1$year)
```

```{r} 
coplot(hits ~ year|NAME, type="b", data=data1, ylab = "GSVI") # Points and lines
# almost in all states the increasing trend for 2018-2019
```

```{r}
density(data1$hits)

# Add a Normal Curve (Thanks to Peter Dalgaard)
z <- data1$hits 
h<-hist(z, breaks=10, col="black", xlab="GSVI", 
   main="Histogram with Normal Curve") 
zfit<-seq(min(z),max(z),length=40) 
yfit<-dnorm(zfit,mean=mean(z),sd=sd(z)) 
yfit <- yfit*diff(h$mids[1:2])*length(z) 
lines(zfit, yfit, col="blue", lwd=2)

library(moments)
skewness(data1$hits)
kurtosis(data1$hits)
# normal kurtosis = 3, skewness = 0

qqnorm(data1$hits, pch = 1, frame = FALSE, main = "Normal Q-Q plot for GSVI of knee brace")
qqline(data1$hits, col = "steelblue", lwd = 2)
 
```

```{r}
outliers <- boxplot(data1$hits, plot=FALSE)$out
d_knee<-data1
d_knee<- d_knee[-which(d_knee$hits %in% outliers),]
```

# After deleting outliers
```{r}
library(moments)
skewness(d_knee$hits)
kurtosis(d_knee$hits)
# normal kurtosis = 3, skewness = 0

qqnorm(d_knee$hits, pch = 1, frame = FALSE, main = "Normal Q-Q plot for GSVI of knee brace")
qqline(d_knee$hits, col = "steelblue", lwd = 2)
```


```{r}
plotmeans(hits ~ NAME, data = d_knee)  
# plotmeans draw a 95% confidence interval around the means
plotmeans(hits ~ year, data = d_knee)
```
# heterogeneity test
```{r} 
bartlett.test(hits ~ NAME, data = data1)
leveneTest(hits ~ NAME, data = data1)
fligner.test(hits ~ NAME, data = data1)
```
# in two test of tree the heterogeneoty does not appear

--------------------------
OLS
--------------------------
```{r}
data_without = data1 %>% dplyr::select(-NAME, -year)
ols_knee <- lm(hits~., data_without)
summary(ols_knee)
vif(ols_knee)

yhat <- ols_knee$fitted
plot(data1$hits, yhat, xlab = "Real values", ylab = "Fitted values", main = "Fitted vs Real values for knee braces")
```

# we have panel data and need to use random or fixed effect model
```{r}
library(plm)
n <- names(data_without)  
f <- as.formula(paste("hits ~ ", paste(n[!n %in% "hits"], collapse = " + ")))

# fixed effects
fixed_knee <- plm(f, 
                 data = data1,  
                 index = c("NAME", "year"), 
                 model = "within")
library(broom) 
summary(fixed_knee)
```


#Check for cross-sectional dependence
```{r}
pcdtest(fixed_knee, test = c("lm")) # cross-sectional dependence exists

# According to Baltagi, cross-sectional dependence is a problem in macro panels with long time series. This is not much of a problem in micro panels (few years and large number of cases).
```

```{r}
# print summary using robust standard errors
coeftest(fixed_knee, vcov. = vcovHC, type = "HC1") 
# HC1 - Recommended for small samples
```

Chech if fixed effects or OLS should be used
```{r} 
pFtest(fixed_knee, ols_knee) # we need to use fixed
```

Random effects
```{r} 
random_knee <- plm(f, data=data1, index=c("NAME", "year"), model="random")
summary(random_knee)
```

Check if random or fixed should be used
```{r}
phtest(fixed_knee, random_knee) 
# fixed effects should be used
```

```{r} 
# print summary using robust standard errors
coeftest(random_model, vcov. = vcovHC, type = "HC1") 
# HC3 - Recommended for small samples and gives less weighs to influential factors
```
 
```{r} 
yhat_rand = random_knee$fitted
plot(data1$hits, yhat_rand)
```

check for heteroscedasticity 
```{r}
bptest(hits ~ latitude + longitude + temperature_celcius + precipitation_inches + 
    perc_white + perc_black + perc_asian + perc_household_inc_less_10 + 
    perc_household_inc_10_14 + perc_household_inc_15_19 + perc_household_inc_20_24 + 
    perc_household_inc_25_29 + perc_household_inc_30_34 + perc_household_inc_35_39 + 
    perc_household_inc_40_44 + perc_household_inc_45_49 + perc_household_inc_50_59 + 
    perc_household_inc_60_74 + perc_household_inc_75_99 + perc_household_inc_100_124 + 
    perc_household_inc_125_149 + perc_household_inc_150_199 + 
    perc_household_inc_200_more + perc_man_bus_sc_occ + perc_serv_occ + 
    perc_sal_off_occ + perc_constr_occ + perc_prod_transp_occ + 
    perc_mil_occ + perc_pr_wage_sal_work + perc_local_govern_work + 
    perc_stat_govern_work + perc_fed_govern_work + perc_self_empl + 
    perc_unpaid_fam_work + perc_never_marr + perc_marr + perc_div_sep_wid + 
    perc_fem_0_9 + perc_fem_10_17 + perc_fem_18_21 + perc_fem_22_29 + 
    perc_fem_30_39 + perc_fem_40_49 + perc_fem_50_59 + perc_fem_60_66 + 
    perc_fem_67_79 + perc_fem_80_85 + perc_mal_30_39 + perc_mal_40_49 + 
    perc_mal_50_59 + perc_mal_60_66 + perc_mal_67_79 + perc_mal_80_85 + factor(NAME), data = data1, studentize=F)
# heteroscedasticity
```

```{r}
g = names(data1) 
ye <- as.formula(paste("hits ~", paste(g[!g %in% "hits"], collapse = " + ")))
fixed.time_knee <- plm(ye, 
                 data = data1,  
                 index = c("NAME", "year"), 
                 model = "within")
summary(fixed.time_knee)
pFtest(fixed.time_knee, fixed_knee)  

plmtest(fixed_knee, c("time"), type=("bp")) 
# time effect does need to be used
```

# Compare the models
```{r}
library(jtools)
library(stargazer)
stargazer(ols_knee, fixed_knee, fixed.time, random_knee, type = "text")
```

----------------------------
Multilevel model
----------------------------
```{r}
# We have a random intercept (which allows the intercept to vary across clusters).
library(lme4)
mult_knee <- lmer( hits ~ latitude + longitude + temperature_celcius + precipitation_inches +     perc_white + perc_black + perc_asian + perc_man_bus_sc_occ +     perc_serv_occ + perc_sal_off_occ + perc_constr_occ + perc_prod_transp_occ +     perc_mil_occ + perc_pr_wage_sal_work + perc_local_govern_work +     perc_stat_govern_work + perc_fed_govern_work + perc_self_empl +     perc_unpaid_fam_work + perc_marr + perc_div_sep_wid + perc_fem_0_9 +     perc_fem_10_17 + perc_fem_18_21 + perc_fem_22_29 + perc_fem_30_39 +     perc_fem_40_49 + perc_fem_50_59 + perc_fem_60_66 + perc_fem_67_79 +     perc_fem_80_85 + perc_mal_30_39 + perc_mal_40_49 + perc_mal_50_59 +     perc_mal_60_66 + perc_mal_67_79 + perc_mal_80_85 + perc_household_income_less_14 +     perc_household_income_15_24 + perc_household_income_25_34 +     perc_household_income_35_44 + perc_household_income_45_59 +     perc_household_income_60_99 + perc_household_income_100_149 +     perc_household_income_150_more + (1 | NAME),
               data = data1,
               REML = FALSE)
summary(mult_knee)
```
```{r}
summ(mult_knee)
```

```{r}
confint(mult_knee)
library(merTools)

predictInterval(mult_knee)   # for various model predictions, possibly with new data

REsim(mult_knee)             # mean, median and sd of the random effect estimates

plotREsim(REsim(mult_knee)) + labs(title = "Plot of Random Effects for knee brace") # plot the interval estimates
```

## transforming into DUMMY -> states and year
```{r}
binary_state <- to.dummy(data1$NAME, "state") # convert character variables into dummy
binary_state = as.data.frame(binary_state) 
binary_state = binary_state %>% mutate(NAME = data1$NAME)
 
pen_knee = data1 %>% inner_join(binary_state) %>% unique() 

#binary_year <- to.dummy(data$year, "year") # convert character variables into dummy
#binary_year = as.data.frame(binary_year) 
#binary_year = binary_year %>% mutate(year = data$year)
 
#data1 = data1 %>% inner_join(binary_year) %>% unique() 

pen_knee = pen_knee %>% dplyr::select(-year, -NAME)
# Classes
length(grep("state.", names(pen_knee), value=TRUE)) #dummy 
state = grep("state.", names(pen_knee), value=TRUE)
#year = grep("year.", names(data1), value=TRUE)
```

## Cross-validation
```{r}  
library(caret)
ctrlspecs_lm <- trainControl(method = "cv", number =10, savePredictions = "all")
```

```{r}  
model2 <- train(hits ~., data = pen_knee, preprocess = c("center", "scale"), method = "lm", trControl = ctrlspecs_lm, na.action=na.omit)
```
# Variable importance

```{r}
ols_imp <- varImp(model2)
ols_imp
ggplot(varImp(model2))
```

```{r}
coeftest(model2, vcov. = vcovHC, type = "HC1")
```

```{r}
predictions2 <- predict(random_model, newdata = pen_knee)
```

# model performance/accuracy
```{r}
library(MLmetrics)
Modelperf2 <- data.frame(MSE = MSE(predictions2, pen_knee$hits), RMSE = RMSE(predictions2, pen_knee$hits), Rsq = R2(predictions2, pen_knee$hits))
Modelperf2
```

--------------------------------
RIDGE
--------------------------------

http://www.science.smith.edu/~jcrouser/SDS293/labs/lab10-r.html
```{r}  
pen_knee = as.data.frame(pen_knee)

x = model.matrix(hits~., pen_knee)[,-1] # trim off the first column
                                         # leaving only the predictors
y = pen_knee %>%
  dplyr::select(hits) %>%
  unlist() %>%
  as.numeric()
```

```{r}
library(ISLR)
library(glmnet)

grid = 10^seq(10, -2, length = 300)
ridge_mod = glmnet(x, y, alpha = 0, lambda = grid)
```

```{r}
dim(coef(ridge_mod))
plot(ridge_mod)    # Draw plot of coefficients
plot(ridge_mod, xvar = "lambda", label = TRUE)
plot(ridge_mod, xvar = "dev", label = TRUE)
```
# from 5th lambda the coefficients are becoming much closer to zero

# Next we fit a ridge regression model using  λ=4
# predictions for a test set, by replacing type="coefficients" with the newx argument.
```{r} 
ridge_pred4 = predict(ridge_mod, s = 4, newx = x)

ridge_4 <- data.frame(regr = "ridge_l4", MSE = MSE(ridge_pred4, pen_knee$hits), RMSE = RMSE(ridge_pred4, pen_knee$hits), Rsq = R2(ridge_pred4, pen_knee$hits), mean_coeff = mean(predict(ridge_mod, s = 4, type = "coefficients")))
ridge_4
```

# We get better result by fitting a ridge regression model with a very large value of  λ
# Note that 1e10 means 1010
```{r}
ridge_pred_large = predict(ridge_mod, s = 1e10, newx = x)
mean((ridge_pred_large - y)^2)

ridge_1010 <- data.frame(regr = "ridge_l1010", MSE = MSE(ridge_pred_large, pen_knee$hits), RMSE = RMSE(ridge_pred_large, pen_knee$hits), Rsq = R2(ridge_pred_large, pen_knee$hits), mean_coeff = mean(predict(ridge_mod, s = 1e10, type="coefficients")))
ridge_1010
```
 
# Now, if we will try with s = 0 with penalty 0
```{r}
# The coefficients are unregularized when lambda is zero
ridge_pred0 = predict(ridge_mod, s = 0, newx = x)  

ridge_0 <- data.frame(regr = "ridge_l0", MSE = MSE(ridge_pred0, pen_knee$hits), RMSE = RMSE(ridge_pred0, pen_knee$hits), Rsq = R2(ridge_pred0, pen_knee$hits), mean_coeff = mean(predict(ridge_mod, s = 0, type="coefficients")))
ridge_0
```

# Instead of arbitrarily choosing  λ, it would be better to use cross-validation to choose the tuning parameter  λ
# We can do this using the built-in cross-validation function, cv.glmnet(). By default, the function performs 10-fold cross-validation, though this can be changed using the argument folds. Note that we set a random seed first so our results will be reproducible, since the choice of the cross-validation folds is random.

```{r} 
cv.out = cv.glmnet(x, y, alpha = 0)  
bestlam = cv.out$lambda.min  # Select lambda that minimizes training MSE
bestlam

plot(cv.out) # Draw plot of training MSE as a function of lambda  
```
# best lambda
```{r}
ridge_pred_cv = predict(ridge_mod, s = bestlam, newx = x) # Use best lambda to predict test data
```

```{r}
ridge_bestlamb <- data.frame(regr = "ridge_cv", MSE = MSE(ridge_pred_cv, pen_knee$hits), RMSE = RMSE(ridge_pred_cv, pen_knee$hits), Rsq = R2(ridge_pred_cv, pen_knee$hits), mean_coeff = mean(predict(ridge_mod, type = "coefficients", s = bestlam))) # Display coefficients using lambda chosen by CV
ridge_bestlamb
```

```{r}
ridge_comp <- rbind(ridge_0, ridge_4, ridge_1010, ridge_bestlamb)
ridge_comp
```

Ridge (method = 2)

```{r} 
library(caret)
ctrlspecs_r <- trainControl(method = "cv", number =10, savePredictions = "all")
```

# sed seed
# Specify lasso regr model to be estimated using training data and 10-fold cv framework
```{r}
model0 <- train(hits ~ ., data = pen_knee, preprocess = c("center", "scale"), method = "glmnet", 
                tuneGrid = expand.grid(alpha = 0, lambda = grid), trControl = ctrlspecs_r, 
                na.action = na.omit)
```

# Best (optimal) tuning parameter (alpha, lambda)
```{r}
model0$bestTune
model0$bestTune$lambda
```

# Variable importance

```{r}
ridge_imp <- varImp(model0)
ridge_imp
ggplot(varImp(model0)) 
```
# Model prediction
```{r}
predictions0 <- predict(model0, newdata = pen_knee)
```

# model performance/accuracy
```{r}
library(MLmetrics)
Modelperf0 <- data.frame(MSE = MSE(predictions0, pen_knee$hits), RMSE = RMSE(predictions0, pen_knee$hits), Rsq = R2(predictions0, pen_knee$hits))
Modelperf0
```

-----------------------------------------------------------
LASSO
-----------------------------------------------------------

```{r} 
lasso_mod = glmnet(x, y, 
                   alpha = 1, 
                   lambda = grid)  

```

```{r}
plot(lasso_mod)    # Draw plot of coefficients
plot(lasso_mod, xvar = "lambda", label = TRUE) # as lambda become larger, the coeff are decreasing
plot(lasso_mod, xvar = "dev", label = TRUE) # Goodness of fit. This plot tells us how much of the deviance which is similar to R-squared has been explained by the model.
```
````{r}
print(lasso_mod)
```

```{r} 
lasso_pred_05 = predict(lasso_mod, s = 0.5, newx = x)


lasso_05 <- data.frame(regr = "lasso_l0.5", MSE = MSE(lasso_pred_05, data1$hits), RMSE = RMSE(lasso_pred_05, data1$hits), Rsq = R2(lasso_pred_05, data1$hits), mean_coeff = mean(predict(lasso_mod, type = "coefficients", s = 0.5)))
lasso_05
```

# look at the coefficients with a given lambda
```{r}  
lasso_coeff_05 <- predict(lasso_mod, type = "coefficients", s = 0.5)
lasso_coeff_05[lasso_coeff_05 != 0]
```
 
# Notice that in the coefficient plot that depending on the choice of tuning parameter, some of the coefficients are exactly equal to zero. We now perform cross-validation and compute the associated test error:

```{r} 
cv.out = cv.glmnet(x, y, alpha = 1)  
plot(cv.out) # Draw plot of training MSE as a function of lambda. Cross validation will indicate which variables to include and picks the coefficients from the best model.

bestlam = cv.out$lambda.min # Select lambda that minimizes training MSE
lasso_pred_cv = predict(lasso_mod, s = bestlam, newx = x) # Use best lambda for full dataset
```

```{r}
lasso_cv <- data.frame(regr = "cv", MSE = MSE(lasso_pred_cv, data1$hits), RMSE = RMSE(lasso_pred_cv, data1$hits), Rsq = R2(lasso_pred_cv, data1$hits), mean_coeff = mean(predict(lasso_mod, type = "coefficients", s = bestlam)))
lasso_cv
```

# This is substantially lower than the test set MSE of the least squares, and very similar to the test MSE of ridge regression with  λ chosen by cross-validation.
# However, the lasso has a substantial advantage over ridge regression in that the resulting coefficient estimates are sparse. Here we see that 20 of the 171 coefficient estimates are exactly zero:

```{r}
lasso_coeff_cv <- predict(lasso_mod, type = "coefficients", s = bestlam)
lasso_coeff_cv[lasso_coeff_cv != 0]# Display only non-zero coefficients
```

```{r}
lasso_pred_50 = predict(lasso_mod, s = 50, newx = x)


lasso_50 <- data.frame(regr = "lasso_l50", MSE = MSE(lasso_pred_50, pen_knee$hits), RMSE = RMSE(lasso_pred_50, pen_knee$hits), Rsq = R2(lasso_pred_50, pen_knee$hits), mean_coeff = mean(predict(lasso_mod, type = "coefficients", s = 50))) 
lasso_50
```

```{r}
lasso_comp <- rbind(lasso_05, lasso_50, lasso_cv)
lasso_comp
```

LASSO (method 2)

```{r}  
ctrlspecs <- trainControl(method = "cv", number =10, savePredictions = "all")
```

# Specify lasso regr model to be estimated using training data and 10-fold cv framework
```{r} 
model1 <- train(hits ~ ., data = pen_knee, preprocess = c("center", "scale"), method = "glmnet", 
                tuneGrid = expand.grid(alpha = 1, lambda = grid), trControl = ctrlspecs, 
                na.action = na.omit)
```

# Best (optimal) tuning parameter (alpha, lambda)
```{r}
model1$bestTune
model1$bestTune$lambda
```

# Variable importance

```{r}
lasso_imp <- varImp(model1)
lasso_imp
ggplot(varImp(model1))
```
  
# Model prediction
```{r}
predictions1 <- predict(model1, newdata = pen_knee) 
```

# model performance/accuracy
```{r}
Modelperf1 <- data.frame(MSE = MSE(predictions1, pen_knee$hits), RMSE = RMSE(predictions1, pen_knee$hits), Rsq = R2(predictions1, pen_knee$hits))
Modelperf1
```



# compare models using paired-samples (one-sample) t-test
```{r}

compare_models(model0, model1, metric = "RMSE")
compare_models(model0, model1, metric = "Rsquared")

compare_models(model1, model2, metric = "RMSE")
compare_models(model1, model2, metric = "Rsquared")
```

# compare model0, model1 and model2 predictive performance  
```{r}
comp <- matrix(c(Modelperf0$MSE, Modelperf0$RMSE,  Modelperf0$Rsq,
                 Modelperf1$MSE, Modelperf1$RMSE,  Modelperf1$Rsq, 
                 Modelperf2$MSE, Modelperf2$RMSE, Modelperf2$Rsq), 
               ncol=3, byrow=TRUE)
colnames(comp) <- c("MSE", "RMSE", "R-square")
rownames(comp) <- c("Ridge regression", "LASSO regression", "OLS")
comp
```

```{r}
lasso_imp
ridge_imp
ols_imp
```

```{r}
summary(model0)
```
#standard errors are not very meaningful for strongly biased estimates such as arise from penalized estimation methods. Penalized estimation is a procedure that reduces the variance of estimators by introducing substantial bias. The bias of each estimator is therefore a major component of its mean squared error, whereas its variance may contribute only a small part.

#Unfortunately, in most applications of penalized regression it is impossible to obtain a sufficiently precise estimate of the bias. Any bootstrap-based calculations can only give an assessment of the variance of the estimates. Reliable estimates of the bias are only available if reliable unbiased estimates are available, which is typically not the case in situations in which penalized estimates are used.

https://cran.r-project.org/web/packages/penalized/vignettes/penalized.pdf

#Among the (few) strategies, including the post-selective inference and the (modified) residual bootstrap, here we illustrate the R package islasso implementing the recent `quasi’ lasso approach based on the induced smoothing idea (Brown and Wang, 2005) as discussed in Cilluffo et al. (2019)
```{r}
library(islasso)
check <- islasso(hits ~ ., data = data1, lambda = bestlam)
summary(check, pval = 0.1)

# http://rstudio-pubs-static.s3.amazonaws.com/567388_f112441d059a48c9905196cae2680ed3.html
```

```{r}
library(plotmo)
plotres(model0, which=1:4)
```
 

```{r}
plotres(model1, which=1:4)
```

```{r}
plotres(ols, which=1:4)
```

----------------------
## linear mixed model
```{r}
lm1 <- glmmLasso(points ~ transfer.spendings + ave.unfair.score
+ ball.possession + tackles
+ ave.attend + sold.out, rnd = list(team=~1), lambda=10, data = soccer)
```
----------------------
GROUP LASSO
---------------------

```{#r}
library(grpreg)
group <- rep(data1)
group
 
fit <- grpreg(x, y, group, penalty="grLasso")

http://www.biostat.umn.edu/~weip/course/dm/examples/exampleforhighd1.R 
https://www.youtube.com/watch?v=2Cj_L1I2JIo 
https://cran.r-project.org/web/packages/grpreg/vignettes/getting-started.html
````